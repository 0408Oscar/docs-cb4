<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_cn2_5ck_r5">
    <title>Release notes</title><shortdesc>Release notes for the 2.0 version of the Kafka connector.</shortdesc>
    <conbody>
    <section>
        <title>Couchbase Kafka Connector 2.0.0 GA (30 March 2016)</title>
        <p>Version 2.0.0 is the general availability (GA) release of the Kafka connector.
            It contains important stability fixes, and also new API.
        </p>

        <p><b>New features and behavioral changes</b></p>
                <p>This release contains the following features:</p>
                <ul>
                    <li>
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-27" format="html" scope="external">KAFKAC-27</xref>,
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-29" format="html" scope="external">KAFKAC-29</xref>,
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-32" format="html" scope="external">KAFKAC-32</xref>,
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-30" format="html" scope="external">KAFKAC-30</xref>,
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-33" format="html" scope="external">KAFKAC-33</xref>:
                        All these issues has common problem that Kafka consumer handles new events on slower rate than DCP producer can emit data.
                        All extra messages was dropped silently, and because most of them were carrying native buffers, which cannot be freed by GC,
                        eventually connector died from out of memory exceptions. To fix these issues, the implementation of DCP handler inside core
                        was revisited, and some of the classes has been removed (like <codeph>BucketStreamAggregator</codeph> and
                        <codeph>BucketStreamAggregatorState</codeph>. Instead more clean alternatives has been introduced
                        (<codeph>ConnectorState</codeph> and <codeph>StreamState</codeph>), which incapsulate only one point in history,
                        instead starting and ending sequence number. In turn this allowed to replace unobvious direction and run mode API, with method
                        accepting two states and number of helper methods which make it easier to initialize <codeph>ConnectorState</codeph>.
                        For example following code
			<codeblock outputclass="language-java"><![CDATA[BucketStreamAggregatorState state = connector.buildState(Direction.TO_CURRENT);
connector.run(state, RunMode.RESUME);
]]></codeblock>
                        can be simplified as
			<codeblock outputclass="language-java"><![CDATA[ConnectorState startState = connector.startState();
ConnectorState currentState = connector.currentState();
connector.run(startState, currentState);
]]></codeblock>
                        And snippet
			<codeblock outputclass="language-java"><![CDATA[BucketStreamAggregatorState state = connector.buildState(Direction.FROM_CURRENT);
connector.run(state, RunMode.LOAD_AND_RESUME);
]]></codeblock>
                        will become
			<codeblock outputclass="language-java"><![CDATA[ConnectorState loadedState = connector.loadState();
ConnectorState endState = connector.endState();
connector.run(loadedState, endState);
]]></codeblock>
                    </li>
                    <li>
                        <xref href="https://www.couchbase.com/issues/browse/KAFKAC-32" format="html" scope="external">KAFKAC-32</xref>:
                        Zookeeper state serializer now use <codeph>/</codeph> (forward slash) as path separator, which make it platform independent (previously connector running on Windows would use backward slash).
                    </li>
                </ul>
            </section>
    </conbody>
</concept>
